{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bütün Modeller İçin Kullanılacak Ortak Test Verisetinin Hazırlanması\n",
    "\n",
    "Burada bütün modellerde ayrılan, Train ve Test'in test kısmını alarak Majority Vote'da test edilmesini sağlayacağız.\n",
    "- Verisetini import ettikten sonra kategorikleri Numerik yaparak Bütün modeller için hazır hale getiriyoruz. Tabii, Derin öğrenme ve Olasılık Bazlı modeller kendi içerisinde özel birkaç ayar daha yapıyorlar, onlarında fonksiyonları bulunmakta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verisetinin import edilmesi, duplicate değerler'in düşürülmesi\n",
    "test = pd.read_excel(\"../Datasets/X_test.xlsx\")\n",
    "test = test.drop_duplicates()\n",
    "target = test.Churn\n",
    "test.drop(\"Churn\", axis=1, inplace=True)\n",
    "features = list(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kategorik verilerin numerik hale getirilmesi\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "objects = [\"SON5ISTIHBARAT_SONUC\",\"SON5POLITIKA_SONUC\",\"SON5CEK_RENK_ORTALAMASI\",\"SON5KULLANDIRIM\",\"ŞUBE\",\"SIRKET_TURU\"]\n",
    "for i in objects:  \n",
    "    test[i] = le.fit_transform(test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geleneksel ML Modeli\n",
    "\n",
    "Direkt pickle ile modeli çekip test verisi sonuçlarına bakıyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.15, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=137,\n",
       "              presort='auto', random_state=51, subsample=0.7, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traditionalml = pickle.load(open('../Model Pickle/traditionalml.sav', 'rb'))\n",
    "traditionalml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[1110   62]\n",
      " [ 182  221]]\n",
      "accuracy_score:  0.8450793650793651\n"
     ]
    }
   ],
   "source": [
    "y_pred = traditionalml.predict(test)\n",
    "cm = confusion_matrix(target, y_pred)\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olasılık Bazlı ML Modeli\n",
    "Olasılık bazlı modeli direkt çekerek gerekli fonksiyonları tanımlayarak test verisinde denemesini yapıyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.15, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=51, subsample=0.7, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olasilikbazli = pickle.load(open('../Model Pickle/olasilikbazlimodel.sav', 'rb'))\n",
    "olasilikbazli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(a):\n",
    "    data=list(a.values())\n",
    "    colz=list(a.keys())\n",
    "    dfx=pd.DataFrame(data=[data], columns=colz)\n",
    "    \n",
    "    XX1 =np.array(dfx)\n",
    "    XX2=dfx[features]\n",
    "    XX = np.hstack((XX1))\n",
    "    return XX\n",
    "\n",
    "\n",
    "def cutoff(x):\n",
    "    if x >= 0.50:\n",
    "        return 1\n",
    "    if x <= 0.50:\n",
    "        return 0\n",
    "    \n",
    "def listdegerverme(liste):\n",
    "    probs = []\n",
    "    for i in liste:\n",
    "        a = {'CEK_TUTAR':test.CEK_TUTAR[i], 'VADE_GUN':test.VADE_GUN[i], 'SON5ISTIHBARAT_SONUC':test.SON5ISTIHBARAT_SONUC[i], \n",
    "             'SON5POLITIKA_SONUC':test.SON5POLITIKA_SONUC[i],'SON5CEK_RENK_ORTALAMASI':test.SON5CEK_RENK_ORTALAMASI[i], \n",
    "             'SON5KULLANDIRIM':test.SON5KULLANDIRIM[i], 'ŞUBE':test.ŞUBE[i], 'SIRKET_TURU':test.SIRKET_TURU[i],\n",
    "             'MUSTERI_RISK_SEVIYESI':test.MUSTERI_RISK_SEVIYESI[i], 'TK_KURUMSAYISISON5':test.TK_KURUMSAYISISON5[i], \n",
    "             'TK_GECIKMEHESAPSON5':test.TK_GECIKMEHESAPSON5[i],\n",
    "             'TK_GECIKMEBAKIYEORT':test.TK_GECIKMEBAKIYEORT[i], 'TK_NAKDILIMIT':test.TK_NAKDILIMIT[i],\n",
    "             'TK_NAKDIRISK':test.TK_NAKDIRISK[i],'TK_GAYRINAKDILIMIT':test.TK_GAYRINAKDILIMIT[i],\n",
    "             'BK_KURUMSAYISI':test.BK_KURUMSAYISI[i],'BK_LIMIT':test.BK_LIMIT[i],\n",
    "             'BK_RISK':test.BK_RISK[i],'BK_GECIKMEHESAP':test.BK_GECIKMEHESAP[i],\n",
    "             'BK_GECIKMEBAKIYE':test.BK_GECIKMEBAKIYE[i],'T2_NAKDILIMIT_TPL':test.T2_NAKDILIMIT_TPL[i],\n",
    "             'T2_NAKDIRISK_TPL':test.T2_NAKDIRISK_TPL[i], 'T2_NAKDIRISK_KV':test.T2_NAKDIRISK_KV[i],\n",
    "             'T2_GAYRINAKDILIMIT':test.T2_GAYRINAKDILIMIT[i],'T2_GAYRINAKDIRISK':test.T2_GAYRINAKDIRISK[i], \n",
    "             'T2_FKTRNG_LIMIT':test.T2_FKTRNG_LIMIT[i],'T2_FKTRNG_TPLRISK':test.T2_FKTRNG_TPLRISK[i],\n",
    "             'T2_NAKDIRISK_OV':test.T2_NAKDIRISK_OV[i],'T2_NAKDIRISK_UV':test.T2_NAKDIRISK_UV[i],\n",
    "             'T2_SORUNLUKOD_RISK':test.T2_SORUNLUKOD_RISK[i],'T3_NAKDILIMIT_TPL':test.T3_NAKDILIMIT_TPL[i],\n",
    "             'T3_NAKDIRISK_TPL':test.T3_NAKDIRISK_TPL[i],'T3_NAKDIRISK_KV':test.T3_NAKDIRISK_KV[i],\n",
    "             'T3_NAKDIRISK_OV':test.T3_NAKDIRISK_OV[i], 'T3_NAKDIRISK_UV':test.T3_NAKDIRISK_UV[i],\n",
    "             'T3_GAYRINAKDILIMIT':test.T3_GAYRINAKDILIMIT[i],'T3_GAYRINAKDIRISK':test.T3_GAYRINAKDIRISK[i],\n",
    "             'T3_FKTRNG_LIMIT':test.T3_FKTRNG_LIMIT[i],'T3_SORUNLUKOD_RISK':test.T3_SORUNLUKOD_RISK[i],\n",
    "             'T3_FKTRNG_TPLRISK':test.T3_FKTRNG_TPLRISK[i], 'T4_NAKDILIMIT_TPL':test.T4_NAKDILIMIT_TPL[i],\n",
    "             'T4_NAKDIRISK_TPL':test.T4_NAKDIRISK_TPL[i],'T4_NAKDIRISK_KV':test.T4_NAKDIRISK_KV[i],\n",
    "             'T4_NAKDIRISK_OV':test.T4_NAKDIRISK_OV[i],'T4_NAKDIRISK_UV':test.T4_NAKDIRISK_UV[i],\n",
    "             'T4_GAYRINAKDILIMIT':test.T4_GAYRINAKDILIMIT[i],'T4_GAYRINAKDIRISK':test.T4_GAYRINAKDIRISK[i],\n",
    "             'T4_FKTRNG_LIMIT':test.T4_FKTRNG_LIMIT[i],'T4_SORUNLUKOD_RISK':test.T4_SORUNLUKOD_RISK[i],\n",
    "             'T4_FKTRNG_TPLRISK':test.T4_FKTRNG_TPLRISK[i]}\n",
    "        XX=preProcess(a)\n",
    "        XX = XX.reshape(1,-1)\n",
    "        probs.append(olasilikbazli.predict_proba(XX)[:,1][0])\n",
    "    liste = pd.DataFrame(liste)\n",
    "    probs = pd.DataFrame(probs)\n",
    "    testler = pd.concat([probs,liste],axis=1)\n",
    "    testler.columns = [\"Probs\",\"İndex\"]\n",
    "    testler = testler.set_index(\"İndex\")\n",
    "    testler[\"WFunc\"] = None\n",
    "    testler[\"WFunc\"] = testler.Probs.apply(cutoff)\n",
    "    return np.array(testler.WFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[1093   79]\n",
      " [ 220  183]]\n",
      "accuracy_score:  0.8101587301587302\n"
     ]
    }
   ],
   "source": [
    "X_testindex = list(test.index)\n",
    "probs = []\n",
    "for i in X_testindex:\n",
    "    a = {'CEK_TUTAR':test.CEK_TUTAR[i], 'VADE_GUN':test.VADE_GUN[i], 'SON5ISTIHBARAT_SONUC':test.SON5ISTIHBARAT_SONUC[i], \n",
    "         'SON5POLITIKA_SONUC':test.SON5POLITIKA_SONUC[i],'SON5CEK_RENK_ORTALAMASI':test.SON5CEK_RENK_ORTALAMASI[i], \n",
    "         'SON5KULLANDIRIM':test.SON5KULLANDIRIM[i], 'ŞUBE':test.ŞUBE[i], 'SIRKET_TURU':test.SIRKET_TURU[i],\n",
    "         'MUSTERI_RISK_SEVIYESI':test.MUSTERI_RISK_SEVIYESI[i], 'TK_KURUMSAYISISON5':test.TK_KURUMSAYISISON5[i], \n",
    "         'TK_GECIKMEHESAPSON5':test.TK_GECIKMEHESAPSON5[i],\n",
    "         'TK_GECIKMEBAKIYEORT':test.TK_GECIKMEBAKIYEORT[i], 'TK_NAKDILIMIT':test.TK_NAKDILIMIT[i],\n",
    "         'TK_NAKDIRISK':test.TK_NAKDIRISK[i],'TK_GAYRINAKDILIMIT':test.TK_GAYRINAKDILIMIT[i],\n",
    "         'BK_KURUMSAYISI':test.BK_KURUMSAYISI[i],'BK_LIMIT':test.BK_LIMIT[i],\n",
    "         'BK_RISK':test.BK_RISK[i],'BK_GECIKMEHESAP':test.BK_GECIKMEHESAP[i],\n",
    "         'BK_GECIKMEBAKIYE':test.BK_GECIKMEBAKIYE[i],'T2_NAKDILIMIT_TPL':test.T2_NAKDILIMIT_TPL[i],\n",
    "         'T2_NAKDIRISK_TPL':test.T2_NAKDIRISK_TPL[i], 'T2_NAKDIRISK_KV':test.T2_NAKDIRISK_KV[i],\n",
    "         'T2_GAYRINAKDILIMIT':test.T2_GAYRINAKDILIMIT[i],'T2_GAYRINAKDIRISK':test.T2_GAYRINAKDIRISK[i], \n",
    "         'T2_FKTRNG_LIMIT':test.T2_FKTRNG_LIMIT[i],'T2_FKTRNG_TPLRISK':test.T2_FKTRNG_TPLRISK[i],\n",
    "         'T2_NAKDIRISK_OV':test.T2_NAKDIRISK_OV[i],'T2_NAKDIRISK_UV':test.T2_NAKDIRISK_UV[i],\n",
    "         'T2_SORUNLUKOD_RISK':test.T2_SORUNLUKOD_RISK[i],'T3_NAKDILIMIT_TPL':test.T3_NAKDILIMIT_TPL[i],\n",
    "         'T3_NAKDIRISK_TPL':test.T3_NAKDIRISK_TPL[i],'T3_NAKDIRISK_KV':test.T3_NAKDIRISK_KV[i],\n",
    "         'T3_NAKDIRISK_OV':test.T3_NAKDIRISK_OV[i], 'T3_NAKDIRISK_UV':test.T3_NAKDIRISK_UV[i],\n",
    "         'T3_GAYRINAKDILIMIT':test.T3_GAYRINAKDILIMIT[i],'T3_GAYRINAKDIRISK':test.T3_GAYRINAKDIRISK[i],\n",
    "         'T3_FKTRNG_LIMIT':test.T3_FKTRNG_LIMIT[i],'T3_SORUNLUKOD_RISK':test.T3_SORUNLUKOD_RISK[i],\n",
    "         'T3_FKTRNG_TPLRISK':test.T3_FKTRNG_TPLRISK[i], 'T4_NAKDILIMIT_TPL':test.T4_NAKDILIMIT_TPL[i],\n",
    "         'T4_NAKDIRISK_TPL':test.T4_NAKDIRISK_TPL[i],'T4_NAKDIRISK_KV':test.T4_NAKDIRISK_KV[i],\n",
    "         'T4_NAKDIRISK_OV':test.T4_NAKDIRISK_OV[i],'T4_NAKDIRISK_UV':test.T4_NAKDIRISK_UV[i],\n",
    "         'T4_GAYRINAKDILIMIT':test.T4_GAYRINAKDILIMIT[i],'T4_GAYRINAKDIRISK':test.T4_GAYRINAKDIRISK[i],\n",
    "         'T4_FKTRNG_LIMIT':test.T4_FKTRNG_LIMIT[i],'T4_SORUNLUKOD_RISK':test.T4_SORUNLUKOD_RISK[i],\n",
    "         'T4_FKTRNG_TPLRISK':test.T4_FKTRNG_TPLRISK[i]}\n",
    "    XX=preProcess(a)\n",
    "    XX = XX.reshape(1,-1)\n",
    "    probs.append(olasilikbazli.predict_proba(XX)[:,1][0])\n",
    "\n",
    "X_testindex = pd.DataFrame(X_testindex)\n",
    "probs = pd.DataFrame(probs)\n",
    "testler = pd.concat([probs,X_testindex],axis=1)\n",
    "testler.columns = [\"Probs\",\"İndex\"]\n",
    "testler = testler.set_index(\"İndex\")\n",
    "testler[\"WFunc\"] = None\n",
    "testler[\"WFunc\"] = testler.Probs.apply(cutoff)\n",
    "\n",
    "cm = confusion_matrix(target, testler.WFunc)\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(target, testler.WFunc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Yaklaşımı\n",
    "Keras modelinin içeriye import ederek değerlendirmesini yapıyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Model Pickle/model_architecture.json', 'r') as f:\n",
    "    kerasmodel = model_from_json(f.read())\n",
    "\n",
    "kerasmodel.load_weights('../Model Pickle/model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KerasPreProcess(test):\n",
    "    scaler = MinMaxScaler((-1,1))\n",
    "    return scaler.fit_transform(test)\n",
    "\n",
    "def scalers(x):\n",
    "    if x > 0.5:\n",
    "        return 1\n",
    "    if x <= 0.5:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = KerasPreProcess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[1078   94]\n",
      " [ 219  184]]\n",
      "accuracy_score:  0.8012698412698412\n"
     ]
    }
   ],
   "source": [
    "y_pred = kerasmodel.predict(test2)\n",
    "y_pred = (y_pred > 0.5) * 1\n",
    "\n",
    "cm = confusion_matrix(target, y_pred)\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Vote Algoritması\n",
    "Burada ise majority vote algoritması kuruluyor. Şu şekilde işliyor\n",
    "\n",
    "- Bütün modeller verilen test verisi için sonuçları çıkartıyor.\n",
    "- Bütün sonuçlar bir dataframede yan yana geliyor, ve Oylar sayılıp, kişinin churn edip etmeyeceği belirleniyor\n",
    "- Bunun Görselleştirilmiş daha rahat hali için Sunum'un **14. Slaytına** bakabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MajorityVote(test):\n",
    "    olasiliksonuc = listdegerverme(list(test.index))\n",
    "    gelenekselml = traditionalml.predict(test)\n",
    "    kerassonuc = kerasmodel.predict(KerasPreProcess(test))\n",
    "    for i in range(0,len(kerassonuc)):\n",
    "        kerassonuc[i] = scalers(kerassonuc[i])\n",
    "    kerassonuc = pd.DataFrame(kerassonuc)\n",
    "    gelenekselml = pd.DataFrame(gelenekselml)\n",
    "    index = pd.DataFrame(list(test.index))\n",
    "    gelenekselml = pd.concat([gelenekselml,index], axis=1)\n",
    "    gelenekselml.columns = [\"Sonuc\",\"İndex\"]\n",
    "    gelenekselml.set_index(\"İndex\")\n",
    "    olasiliksonuc = pd.DataFrame(olasiliksonuc)\n",
    "    gelenekselml = gelenekselml.Sonuc\n",
    "    majority = pd.concat([olasiliksonuc,gelenekselml,kerassonuc],axis=1)\n",
    "    majority[\"Majority\"] = None\n",
    "    majority.columns = [\"Olasilik\",\"Geleneksel\",\"Keras\",\"Majority\"]\n",
    "    for i in range(0,len(majority)):\n",
    "        if majority.Olasilik[i] + majority.Geleneksel[i] + majority.Keras[i] == 3:\n",
    "            majority.Majority[i] = 1\n",
    "        elif majority.Olasilik[i] + majority.Geleneksel[i] + majority.Keras[i] == 2:\n",
    "             majority.Majority[i] = 1\n",
    "        elif majority.Olasilik[i] + majority.Geleneksel[i] + majority.Keras[i]== 1:\n",
    "             majority.Majority[i] = 0\n",
    "        elif majority.Olasilik[i] + majority.Geleneksel[i] + majority.Keras[i]== 0:\n",
    "            majority.Majority[i] = 0\n",
    "    return majority.Majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "Majority = MajorityVote(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bu kısımda ise çıktısını aldığımız majority vote sonucunu gerçek test sonuçları ile karşılaştırarak model'in doğruluğuna bakıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Majority = pd.DataFrame(Majority)\n",
    "index = pd.DataFrame(list(test.index))\n",
    "Majority = pd.concat([Majority,index],axis=1)\n",
    "Majority.columns = [\"Majority\",\"İndex\"]\n",
    "Majority = Majority.set_index(\"İndex\")\n",
    "Majority = Majority.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[1098   74]\n",
      " [ 193  210]]\n",
      "accuracy_score:  0.8304761904761905\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(target, Majority)\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(target, Majority))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
